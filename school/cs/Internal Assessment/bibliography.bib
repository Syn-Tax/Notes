
@article{devlin2019,
  title = {{{BERT}}: {{Pre}}-Training of {{Deep Bidirectional Transformers}} for {{Language Understanding}}},
  shorttitle = {{{BERT}}},
  author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  year = {2019},
  month = may,
  abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pretrain deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be finetuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial taskspecific architecture modifications.},
  archivePrefix = {arXiv},
  eprint = {1810.04805},
  eprinttype = {arxiv},
  file = {/home/oscar/Zotero/storage/L4HICJHI/Devlin et al. - 2019 - BERT Pre-training of Deep Bidirectional Transform.pdf},
  journal = {arXiv:1810.04805 [cs]},
  keywords = {Computer Science - Computation and Language,model},
  language = {en},
  primaryClass = {cs}
}

@article{filighera2020,
  title = {Fooling {{Automatic Short Answer Grading Systems}}},
  author = {Filighera, Anna and Steuer, Tim and Rensing, Christoph},
  year = {2020},
  month = jun,
  volume = {12163},
  pages = {177--190},
  doi = {10.1007/978-3-030-52237-7_15},
  abstract = {With the rising success of adversarial attacks on many NLP tasks, systems which actually operate in an adversarial scenario need to be reevaluated. For this purpose, we pose the following research question: How difficult is it to fool automatic short answer grading systems? In particular, we investigate the robustness of the state of the art automatic short answer grading system proposed by Sung et al. towards cheating in the form of universal adversarial trigger employment. These are short token sequences that can be prepended to students' answers in an exam to artificially improve their automatically assigned grade. Such triggers are especially critical as they can easily be used by anyone once they are found. In our experiments, we discovered triggers which allow students to pass exams with passing thresholds of \textbackslash documentclass[12pt]\{minimal\} 				\textbackslash usepackage\{amsmath\} 				\textbackslash usepackage\{wasysym\}  				\textbackslash usepackage\{amsfonts\}  				\textbackslash usepackage\{amssymb\}  				\textbackslash usepackage\{amsbsy\} 				\textbackslash usepackage\{mathrsfs\} 				\textbackslash usepackage\{upgreek\} 				\textbackslash setlength\{\textbackslash oddsidemargin\}\{-69pt\} 				\textbackslash begin\{document\}\$\$50\textbackslash\%\$\$\textbackslash end\{document\}50\% without answering a single question correctly. Furthermore, we show that such triggers generalize across models and datasets in this scenario, nullifying the defense strategy of keeping grading models or data secret.},
  file = {/home/oscar/Zotero/storage/7J6MJSP6/Filighera et al. - 2020 - Fooling Automatic Short Answer Grading Systems.pdf},
  journal = {Artificial Intelligence in Education},
  pmcid = {PMC7334174},
  pmid = {null}
}

@misc{graves2018,
  title = {Deep {{Learning}} 7. {{Attention}} and {{Memory}} in {{Deep Learning}} - {{YouTube}}},
  author = {Graves, Alex},
  year = {2018},
  month = mar,
  file = {/home/oscar/Zotero/storage/3HNAGSCL/watch.html},
  keywords = {technology}
}

@inproceedings{johanberggren2019,
  title = {Regression or Classification? {{Automated Essay Scoring}} for {{Norwegian}}},
  shorttitle = {Regression or Classification?},
  booktitle = {Proceedings of the {{Fourteenth Workshop}} on {{Innovative Use}} of {{NLP}} for {{Building Educational Applications}}},
  author = {Johan Berggren, Stig and Rama, Taraka and {\O}vrelid, Lilja},
  year = {2019},
  pages = {92--102},
  publisher = {{Association for Computational Linguistics}},
  address = {{Florence, Italy}},
  doi = {10.18653/v1/W19-4409},
  abstract = {In this paper we present first results for the task of Automated Essay Scoring for Norwegian learner language. We analyze a number of properties of this task experimentally and assess (i) the formulation of the task as either regression or classification, (ii) the use of various non-neural and neural machine learning architectures with various types of input representations, and (iii) applying multi-task learning for joint prediction of essay scoring and native language identification. We find that a GRU-based attention model trained in a single-task setting performs best at the AES task.},
  file = {/home/oscar/Zotero/storage/HIE47YW2/Johan Berggren et al. - 2019 - Regression or classification Automated Essay Scor.pdf},
  keywords = {read},
  language = {en}
}

@misc{kim2020,
  title = {Attention in {{Neural Networks}} - 1. {{Introduction}} to Attention Mechanism {$\cdot$} {{Buomsoo Kim}}},
  author = {Kim, Buomsoo},
  year = {2020},
  month = jan,
  howpublished = {https://buomsoo-kim.github.io/attention/2020/01/01/Attention-mechanism-1.md/},
  keywords = {read,technology}
}

@article{lehanyang2019,
  title = {Automated {{Examination Grading Using Deep Learning Categorization Techniques}}},
  author = {Lehan Yang},
  year = {2019},
  publisher = {{Unpublished}},
  doi = {10.13140/RG.2.2.32497.53607},
  file = {/home/oscar/Zotero/storage/YWXF7CV4/Lehan Yang - 2019 - Automated Examination Grading Using Deep Learning .pdf},
  keywords = {read},
  language = {en}
}

@misc{manning2017,
  title = {Lecture 10: {{Neural Machine Translation}} and {{Models}} with {{Attention}}},
  shorttitle = {Lecture 10},
  author = {Manning, Chris and Socher, Richard},
  year = {2017},
  month = apr,
  abstract = {Lecture 10 introduces translation, machine translation, and neural machine translation. Google's new NMT is highlighted followed by sequence models with attention as well as sequence model decoders. ------------------------------------------------------------------------------- Natural Language Processing with Deep Learning Instructors: - Chris Manning - Richard Socher Natural language processing (NLP) deals with the key artificial intelligence technology of understanding complex human language communication. This lecture series provides a thorough introduction to the cutting-edge research in deep learning applied to NLP, an approach that has recently obtained very high performance across many different NLP tasks including question answering and machine translation. It emphasizes how to implement, train, debug, visualize, and design neural network models, covering the main technologies of word vectors, feed-forward models, recurrent neural networks, recursive neural networks, convolutional neural networks, and recent models involving a memory component. For additional learning opportunities please visit: http://stanfordonline.stanford.edu/}
}

@misc{ng2018,
  title = {{{C5W3L08 Attention Model}}},
  author = {Ng, Andrew},
  year = {2018},
  month = feb,
  abstract = {Take the Deep Learning Specialization: http://bit.ly/2PN9yir Check out all our courses: https://www.deeplearning.ai Subscribe to The Batch, our weekly newsletter: https://www.deeplearning.ai/thebatch Follow us:  Twitter: https://twitter.com/deeplearningai\_ Facebook: https://www.facebook.com/deeplearningHQ/ Linkedin: https://www.linkedin.com/company/deep...}
}

@article{nguyen2016,
  title = {Neural {{Networks}} for {{Automated Essay Grading}}},
  author = {Nguyen, Huyen and Dery, Lucio},
  year = {2016},
  pages = {11},
  abstract = {The biggest obstacle to choosing constructed-response assessments over traditional multiple-choice assessments is the large cost and effort required for scoring. This project is an attempt to use different neural network architectures to build an accurate automated essay grading system to solve this problem.},
  file = {/home/oscar/Zotero/storage/EH6UWLBQ/Nguyen and Dery - Neural Networks for Automated Essay Grading.pdf},
  language = {en}
}

@inproceedings{pulman2005,
  title = {Automatic Short Answer Marking},
  booktitle = {Proceedings of the Second Workshop on {{Building Educational Applications Using NLP}} - {{EdAppsNLP}} 05},
  author = {Pulman, Stephen G. and Sukkarieh, Jana Z.},
  year = {2005},
  pages = {9--16},
  publisher = {{Association for Computational Linguistics}},
  address = {{Ann Arbor, Michigan}},
  doi = {10.3115/1609829.1609831},
  file = {/home/oscar/Zotero/storage/CXQI4HWH/Pulman and Sukkarieh - 2005 - Automatic short answer marking.pdf},
  language = {en}
}

@article{ramalingam2018,
  title = {Automated {{Essay Grading}} Using {{Machine Learning Algorithm}}},
  author = {Ramalingam, V. V. and Pandian, A and Chetry, Prateek and Nigam, Himanshu},
  year = {2018},
  month = apr,
  volume = {1000},
  pages = {012030},
  issn = {1742-6588, 1742-6596},
  doi = {10.1088/1742-6596/1000/1/012030},
  abstract = {Essays are paramount for of assessing the academic excellence along with linking the different ideas with the ability to recall but are notably time consuming when they are assessed manually. Manual grading takes significant amount of evaluator's time and hence it is an expensive process. Automated grading if proven effective will not only reduce the time for assessment but comparing it with human scores will also make the score realistic. The project aims to develop an automated essay assessment system by use of machine learning techniques by classifying a corpus of textual entities into small number of discrete categories, corresponding to possible grades. Linear regression technique will be utilized for training the model along with making the use of various other classifications and clustering techniques. We intend to train classifiers on the training set, make it go through the downloaded dataset, and then measure performance our dataset by comparing the obtained values with the dataset values. We have implemented our model using java.},
  file = {/home/oscar/Zotero/storage/2V2HYB96/Ramalingam et al. - 2018 - Automated Essay Grading using Machine Learning Alg.pdf},
  journal = {Journal of Physics: Conference Series},
  language = {en}
}

@inproceedings{sinha2018,
  title = {Answer {{Evaluation Using Machine Learning}}},
  author = {Sinha, Prince and Kaul, Ayush and Bharadia, Sharad},
  year = {2018},
  pages = {7},
  abstract = {In this modern age, where the world moves towards automation so, there is a need for automation in answer evaluation system. Currently, the online answer evaluation is available for mcq based question, hence evaluation of the theory answer is hectic for the checker. Teacher manually checks the answer and allot the marks. The current system takes more manpower and time to evaluate the answer. In this journal an application based on the evaluation of answers using machine learning. The objective of the journal is to specially reduce the manpower and time consumption. Since in manual answer evaluation, the manpower and the time consumption is much more. Also, in the manual system, it may be possible that the marks given to two same answers are different. This application system provides an automatic evaluation of answer based on the keyword provided to the application in form of the input by the moderator which will provide equal distribution of marks and will reduce time and manpower.},
  file = {/home/oscar/Notes/school/cs/Answer_Evaluation_with_ML.pdf},
  language = {en}
}

@inproceedings{taghipour2016,
  title = {A {{Neural Approach}} to {{Automated Essay Scoring}}},
  booktitle = {Proceedings of the 2016 {{Conference}} on {{Empirical Methods}} in {{Natural}}           {{Language Processing}}},
  author = {Taghipour, Kaveh and Ng, Hwee Tou},
  year = {2016},
  pages = {1882--1891},
  publisher = {{Association for Computational Linguistics}},
  address = {{Austin, Texas}},
  doi = {10.18653/v1/D16-1193},
  abstract = {Traditional automated essay scoring systems rely on carefully designed features to evaluate and score essays. The performance of such systems is tightly bound to the quality of the underlying features. However, it is laborious to manually design the most informative features for such a system. In this paper, we develop an approach based on recurrent neural networks to learn the relation between an essay and its assigned score, without any feature engineering. We explore several neural network models for the task of automated essay scoring and perform some analysis to get some insights of the models. The results show that our best system, which is based on long short-term memory networks, outperforms a strong baseline by 5.6\% in terms of quadratic weighted Kappa, without requiring any feature engineering.},
  file = {/home/oscar/Zotero/storage/FI5L8T94/Taghipour and Ng - 2016 - A Neural Approach to Automated Essay Scoring.pdf},
  language = {en}
}

@article{valenti2003,
  title = {An {{Overview}} of {{Current Research}} on {{Automated Essay Grading}}},
  author = {Valenti, Salvatore and Neri, Francesca and Cucchiarelli, Alessandro},
  year = {2003},
  volume = {2},
  pages = {319--330},
  issn = {1547-9714, 1539-3585},
  doi = {10.28945/331},
  abstract = {Essays are considered by many researchers as the most useful tool to assess learning outcomes, implying the ability to recall, organize and integrate ideas, the ability to express oneself in writing and the ability to supply merely than identify interpretation and application of data. It is in the measurement of such outcomes, corresponding to the evaluation and synthesis levels of the Bloom's (1956) taxonomy that the essay questions serve their most useful purpose. One of the difficulties of grading essays is represented by the perceived subjectivity of the grading process. Many researchers claim that the subjective nature of essay assessment leads to variation in grades awarded by different human assessors, which is perceived by students as a great source of unfairness. This issue may be faced through the adoption of automated assessment tools for essays. A system for automated assessment would at least be consistent in the way it scores essays, and enormous cost and time savings could be achieved if the system can be shown to grade essays within the range of those awarded by human assessors. This paper presents an overview of current approaches to the automated assessment of free text answers. Ten systems, currently available either as commercial systems or as the result of research in this field, are discussed: Project Essay Grade (PEG), Intelligent Essay Assessor (IEA), Educational Testing service I, Electronic Essay Rater (E-Rater), C-Rater, BETSY, Intelligent Essay Marking System, SEAR, Paperless School free text Marking Engine and Automark. For each system, the general structure and the performance claimed by the authors are described. In the last section of the paper an attempt is made to compare the performances of the described systems. The most common problems encountered in the research on automated essay grading is the absence both of a good standard to calibrate human marks and of a clear set of rules for selecting master texts. A first conclusion obtained is that in order to really compare the performance of the systems some sort of unified measure should be defined. Furthermore, the lack of standard data collection is identified. Both these problems represent interesting issues for further research in this field.},
  file = {/home/oscar/Zotero/storage/8LA8CP53/Valenti et al. - 2003 - An Overview of Current Research on Automated Essay.pdf},
  journal = {Journal of Information Technology Education: Research},
  language = {en}
}

@article{vaswani2017,
  title = {Attention Is {{All}} You {{Need}}},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  year = {2017},
  pages = {11},
  abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 Englishto-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.0 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature.},
  file = {/home/oscar/Zotero/storage/L74R8KT7/Vaswani et al. - Attention is All you Need.pdf},
  keywords = {technology},
  language = {en}
}

@article{xu2015,
  title = {Show, {{Attend}} and {{Tell}}: {{Neural Image CaptionGeneration}} with {{Visual Attention}}},
  author = {Xu, Kelvin and Lei, Jimmy and Kiros, Ryan and Cho, Kyunghyun and Courville, Aaron and Salakhutdinov, Ruslan and Zemel, Richard S and Bengio, Yoshua},
  year = {2015},
  pages = {10},
  abstract = {Inspired by recent work in machine translation and object detection, we introduce an attention based model that automatically learns to describe the content of images. We describe how we can train this model in a deterministic manner using standard backpropagation techniques and stochastically by maximizing a variational lower bound. We also show through visualization how the model is able to automatically learn to fix its gaze on salient objects while generating the corresponding words in the output sequence. We validate the use of attention with state-of-theart performance on three benchmark datasets: Flickr9k, Flickr30k and MS COCO.},
  file = {/home/oscar/Zotero/storage/VRELXTU8/Xu et al. - Show, Attend and Tell Neural Image CaptionGenerat.pdf},
  keywords = {technology},
  language = {en}
}

@inproceedings{yang2016,
  title = {Hierarchical {{Attention Networks}} for {{Document Classification}}},
  booktitle = {Proceedings of the 2016 {{Conference}} of the {{North American Chapter}} of the {{Association}} for {{Computational Linguistics}}: {{Human Language Technologies}}},
  author = {Yang, Zichao and Yang, Diyi and Dyer, Chris and He, Xiaodong and Smola, Alex and Hovy, Eduard},
  year = {2016},
  pages = {1480--1489},
  publisher = {{Association for Computational Linguistics}},
  address = {{San Diego, California}},
  doi = {10.18653/v1/N16-1174},
  abstract = {We propose a hierarchical attention network for document classification. Our model has two distinctive characteristics: (i) it has a hierarchical structure that mirrors the hierarchical structure of documents; (ii) it has two levels of attention mechanisms applied at the wordand sentence-level, enabling it to attend differentially to more and less important content when constructing the document representation. Experiments conducted on six large scale text classification tasks demonstrate that the proposed architecture outperform previous methods by a substantial margin. Visualization of the attention layers illustrates that the model selects qualitatively informative words and sentences.},
  file = {/home/oscar/Zotero/storage/G4VTDX3W/Yang et al. - 2016 - Hierarchical Attention Networks for Document Class.pdf},
  keywords = {technology},
  language = {en}
}

@article{yang2020,
  title = {{{XLNet}}: {{Generalized Autoregressive Pretraining}} for {{Language Understanding}}},
  shorttitle = {{{XLNet}}},
  author = {Yang, Zhilin and Dai, Zihang and Yang, Yiming and Carbonell, Jaime and Salakhutdinov, Ruslan and Le, Quoc V.},
  year = {2020},
  month = jan,
  abstract = {With the capability of modeling bidirectional contexts, denoising autoencoding based pretraining like BERT achieves better performance than pretraining approaches based on autoregressive language modeling. However, relying on corrupting the input with masks, BERT neglects dependency between the masked positions and suffers from a pretrain-finetune discrepancy. In light of these pros and cons, we propose XLNet, a generalized autoregressive pretraining method that (1) enables learning bidirectional contexts by maximizing the expected likelihood over all permutations of the factorization order and (2) overcomes the limitations of BERT thanks to its autoregressive formulation. Furthermore, XLNet integrates ideas from Transformer-XL, the state-of-the-art autoregressive model, into pretraining. Empirically, under comparable experiment settings, XLNet outperforms BERT on 20 tasks, often by a large margin, including question answering, natural language inference, sentiment analysis, and document ranking.1.},
  archivePrefix = {arXiv},
  eprint = {1906.08237},
  eprinttype = {arxiv},
  file = {/home/oscar/Zotero/storage/CY5M2ASK/Yang et al. - 2020 - XLNet Generalized Autoregressive Pretraining for .pdf},
  journal = {arXiv:1906.08237 [cs]},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning,model},
  language = {en},
  primaryClass = {cs}
}


